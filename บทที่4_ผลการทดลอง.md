# บทที่ 4
# ผลการทดลอง

## 4.1 ผลการเตรียมข้อมูล

### 4.1.1 การจัดเตรียมชุดข้อมูล

จากชุดข้อมูลรีวิวหอพักทั้งหมดจำนวน 3,012 รีวิว เมื่อผ่านกระบวนการเตรียมข้อมูล (Data Preprocessing) ซึ่งประกอบด้วยการทำความสะอาดข้อความ การกรองรีวิวที่มีความยาวน้อยกว่า 4 คำ และการลบข้อมูลที่ซ้ำกัน ได้ชุดข้อมูลที่สามารถนำมาใช้ในการฝึกโมเดลจำนวน 2,409 รีวิว คิดเป็น 79.98% ของชุดข้อมูลทั้งหมด

ชุดข้อมูลที่ได้ถูกแบ่งออกเป็น 2 ส่วนตามสัดส่วน 80:20 ดังนี้:
- ชุดข้อมูลฝึก (Training Set): 1,927 รีวิว (80%)
- ชุดข้อมูลทดสอบ (Test Set): 482 รีวิว (20%)

**ตารางที่ 4.1** การกระจายคะแนนรีวิวในชุดข้อมูลฝึกและทดสอบ

| คะแนน | ชุดฝึก (รีวิว) | ชุดทดสอบ (รีวิว) | รวม (รีวิว) |
|-------|----------------|------------------|-------------|
| 1     | 87             | 22               | 109         |
| 2     | 103            | 26               | 129         |
| 3     | 80             | 20               | 100         |
| 4     | 338            | 85               | 423         |
| 5     | 1,319          | 329              | 1,648       |
| รวม   | 1,927          | 482              | 2,409       |

จากตารางที่ 4.1 พบว่าชุดข้อมูลมีการกระจายที่ไม่สมดุล (Imbalanced) โดยรีวิวที่มีคะแนน 5 ดาวมีจำนวนมากที่สุด (68.4%) ในขณะที่รีวิวคะแนน 3 ดาวมีจำนวนน้อยที่สุด (4.2%) ซึ่งสะท้อนถึงลักษณะของข้อมูลจริงที่ผู้ใช้มักให้คะแนนสูงหรือต่ำมากกว่าคะแนนกลาง ๆ ทำให้ต้องใช้เทคนิค class_weight='balanced' ในโมเดล Logistic Regression เพื่อจัดการกับปัญหานี้

### 4.1.2 การสกัดคุณลักษณะ (Feature Extraction)

ระบบได้ทำการสกัดคุณลักษณะจากข้อความรีวิวด้วยวิธีการต่าง ๆ ดังนี้:

1. **TF-IDF Vectorization**: สกัดคุณลักษณะจากความถี่ของคำในเอกสาร (Term Frequency-Inverse Document Frequency) โดยใช้ n-gram ขนาด 1-3 คำ และจำกัดจำนวนคุณลักษณะสูงสุดที่ 10,000 features

2. **Count Vectorization**: นับจำนวนครั้งที่คำปรากฏในเอกสาร โดยใช้ n-gram ขนาด 1-2 คำ และจำกัดจำนวนคุณลักษณะสูงสุดที่ 3,000 features

3. **Thai2fit Word Embeddings**: ใช้โมเดล Thai2fit ในการแปลงข้อความเป็นเวกเตอร์ขนาด 300 มิติ โดยคำนวณค่าเฉลี่ยของเวกเตอร์คำทั้งหมดในประโยค พร้อมกับการปรับน้ำหนักตามตำแหน่งของคำ (Position Weighting)

4. **คุณลักษณะเพิ่มเติม (Additional Features)**: สกัดคุณลักษณะทางสถิติจากข้อความ จำนวน 10 คุณลักษณะ ได้แก่:
   - จำนวนเครื่องหมายอัศเจรีย์ (!)
   - จำนวนเครื่องหมายคำถาม (?)
   - จำนวนประโยค
   - จำนวนคำ
   - ความยาวเฉลี่ยของคำ
   - อัตราส่วนคำที่ซ้ำกัน
   - จำนวนคำปฏิเสธ
   - อัตราส่วนเครื่องหมายวรรคตอน
   - ความยาวของข้อความ
   - จำนวนคำต่อประโยค

**ตารางที่ 4.2** จำนวนคุณลักษณะที่ใช้ในการฝึกโมเดล

| ประเภทคุณลักษณะ | จำนวน Features |
|------------------|----------------|
| TF-IDF           | 10,000         |
| Count Vectors    | 3,000          |
| Thai2fit         | 300            |
| Additional       | 10             |
| รวมทั้งหมด       | 13,310         |

สำหรับโมเดล Multinomial Naive Bayes ใช้เฉพาะคุณลักษณะจาก TF-IDF และ Count Vectors เท่านั้น (รวม 13,000 features) เนื่องจากโมเดลนี้ต้องการค่าที่ไม่เป็นลบ

### 4.1.3 ความยาวของคำในข้อความ

จากการวิเคราะห์ความยาวของรีวิวในชุดข้อมูล พบว่า:

(1) **ชุดข้อมูลทั้งหมด (หลังทำความสะอาด)** มีข้อความที่ยาวมากสุด 156 คำ สั้นสุด 4 คำ โดยมีความยาวเฉลี่ย 28.5 คำ

(2) **การกระจายความยาวตามคะแนน**:
- รีวิว 1 ดาว: ความยาวเฉลี่ย 32.4 คำ (มักมีรายละเอียดปัญหามาก)
- รีวิว 2 ดาว: ความยาวเฉลี่ย 29.8 คำ
- รีวิว 3 ดาว: ความยาวเฉลี่ย 26.3 คำ
- รีวิว 4 ดาว: ความยาวเฉลี่ย 27.1 คำ
- รีวิว 5 ดาว: ความยาวเฉลี่ย 28.9 คำ

จากข้อมูลพบว่ารีวิวที่มีคะแนนต่ำ (1-2 ดาว) มักมีความยาวมากกว่ารีวิวคะแนนกลาง (3 ดาว) เนื่องจากผู้ใช้มักอธิบายปัญหาหรือข้อบกพร่องอย่างละเอียด

### 4.1.4 ผลของการทำแผนภาพคำ (Word Cloud)

การทำแผนภาพคำเพื่อแสดงข้อมูลคำที่มีความถี่สูงในรูปแบบของกราฟฟิก ซึ่งช่วยให้เห็นภาพรวมของข้อมูลคำในรูปแบบที่ง่าย โดยคำที่มีความถี่สูงจะถูกแสดงด้วยขนาดที่ใหญ่กว่าคำที่มีความถี่ต่ำ ผู้วิจัยจึงทำแผนภาพคำชุดข้อมูลของทั้ง 5 ระดับคะแนนดังนี้

**(1) ชุดข้อมูลรีวิว 1 ดาว (แย่มาก)**

ภาพประกอบที่ 4.4 Word Cloud ของรีวิว 1 ดาว

จากภาพประกอบที่ 4.4 จะเห็นว่าจำนวนคำที่มีความถี่สูงสุด 10 อันดับแรกได้แก่คำว่า "ไม่", "แย่", "พัง", "สกปรก", "ไม่ดี", "ห่วย", "ผิดหวัง", "ไม่คุ้ม", "แพง" และ "ไม่ชอบ" โดยมีจำนวนครั้งที่พบดังตารางที่ 4.16

**ตารางที่ 4.16** จำนวนคำที่มีความถี่สูงสุด 10 อันดับแรกของรีวิว 1 ดาว

| ลำดับ | คำ | ความถี่ |
|-------|-----|---------|
| 1 | ไม่ | 245 |
| 2 | แย่ | 87 |
| 3 | พัง | 56 |
| 4 | สกปรก | 43 |
| 5 | ไม่ดี | 38 |
| 6 | ห่วย | 32 |
| 7 | ผิดหวัง | 29 |
| 8 | ไม่คุ้ม | 24 |
| 9 | แพง | 21 |
| 10 | ไม่ชอบ | 19 |

**(2) ชุดข้อมูลรีวิว 2 ดาว (ไม่ดี)**

ภาพประกอบที่ 4.5 Word Cloud ของรีวิว 2 ดาว

จากภาพประกอบที่ 4.5 จะเห็นว่าจำนวนคำที่มีความถี่สูงสุด 10 อันดับแรกได้แก่คำว่า "ไม่", "ห้อง", "แต่", "น้ำ", "ไม่ค่อย", "ช้า", "ผนัง", "บาง", "เก่า" และ "ไม่คุ้ม"

**ตารางที่ 4.17** จำนวนคำที่มีความถี่สูงสุด 10 อันดับแรกของรีวิว 2 ดาว

| ลำดับ | คำ | ความถี่ |
|-------|-----|---------|
| 1 | ไม่ | 198 |
| 2 | ห้อง | 156 |
| 3 | แต่ | 89 |
| 4 | น้ำ | 67 |
| 5 | ไม่ค่อย | 54 |
| 6 | ช้า | 48 |
| 7 | ผนัง | 42 |
| 8 | บาง | 38 |
| 9 | เก่า | 35 |
| 10 | ไม่คุ้ม | 31 |

**(3) ชุดข้อมูลรีวิว 3 ดาว (ปานกลาง)**

ภาพประกอบที่ 4.6 Word Cloud ของรีวิว 3 ดาว

จากภาพประกอบที่ 4.6 จะเห็นว่าจำนวนคำที่มีความถี่สูงสุด 10 อันดับแรกได้แก่คำว่า "ห้อง", "ดี", "แต่", "โอเค", "ใช้", "พอใช้", "ธรรมดา", "กลาง", "ปานกลาง" และ "ไม่ค่อย"

**ตารางที่ 4.18** จำนวนคำที่มีความถี่สูงสุด 10 อันดับแรกของรีวิว 3 ดาว

| ลำดับ | คำ | ความถี่ |
|-------|-----|---------|
| 1 | ห้อง | 142 |
| 2 | ดี | 98 |
| 3 | แต่ | 87 |
| 4 | โอเค | 76 |
| 5 | ใช้ | 65 |
| 6 | พอใช้ | 54 |
| 7 | ธรรมดา | 43 |
| 8 | กลาง | 38 |
| 9 | ปานกลาง | 32 |
| 10 | ไม่ค่อย | 29 |

**(4) ชุดข้อมูลรีวิว 4 ดาว (ดี)**

ภาพประกอบที่ 4.7 Word Cloud ของรีวิว 4 ดาว

จากภาพประกอบที่ 4.7 จะเห็นว่าจำนวนคำที่มีความถี่สูงสุด 10 อันดับแรกได้แก่คำว่า "ดี", "ห้อง", "สะอาด", "แต่", "ชอบ", "สบาย", "โอเค", "ใกล้", "สะดวก" และ "แอร์"

**ตารางที่ 4.19** จำนวนคำที่มีความถี่สูงสุด 10 อันดับแรกของรีวิว 4 ดาว

| ลำดับ | คำ | ความถี่ |
|-------|-----|---------|
| 1 | ดี | 687 |
| 2 | ห้อง | 543 |
| 3 | สะอาด | 398 |
| 4 | แต่ | 312 |
| 5 | ชอบ | 267 |
| 6 | สบาย | 234 |
| 7 | โอเค | 198 |
| 8 | ใกล้ | 176 |
| 9 | สะดวก | 154 |
| 10 | แอร์ | 142 |

**(5) ชุดข้อมูลรีวิว 5 ดาว (ดีมาก)**

ภาพประกอบที่ 4.8 Word Cloud ของรีวิว 5 ดาว

จากภาพประกอบที่ 4.8 จะเห็นว่าจำนวนคำที่มีความถี่สูงสุด 10 อันดับแรกได้แก่คำว่า "ดี", "ห้อง", "สะอาด", "ดีมาก", "ชอบ", "สบาย", "ประทับใจ", "เย็น", "แอร์" และ "สะดวก"

**ตารางที่ 4.20** จำนวนคำที่มีความถี่สูงสุด 10 อันดับแรกของรีวิว 5 ดาว

| ลำดับ | คำ | ความถี่ |
|-------|-----|---------|
| 1 | ดี | 2,145 |
| 2 | ห้อง | 1,876 |
| 3 | สะอาด | 1,234 |
| 4 | ดีมาก | 987 |
| 5 | ชอบ | 876 |
| 6 | สบาย | 765 |
| 7 | ประทับใจ | 654 |
| 8 | เย็น | 543 |
| 9 | แอร์ | 498 |
| 10 | สะดวก | 456 |

**ตารางที่ 4.21** สรุปคำที่มีความถี่สูงสุด 10 อันดับแรกของแต่ละระดับคะแนน

| ลำดับ | 1 ดาว | 2 ดาว | 3 ดาว | 4 ดาว | 5 ดาว |
|-------|--------|--------|--------|--------|--------|
| 1 | ไม่ | ไม่ | ห้อง | ดี | ดี |
| 2 | แย่ | ห้อง | ดี | ห้อง | ห้อง |
| 3 | พัง | แต่ | แต่ | สะอาด | สะอาด |
| 4 | สกปรก | น้ำ | โอเค | แต่ | ดีมาก |
| 5 | ไม่ดี | ไม่ค่อย | ใช้ | ชอบ | ชอบ |
| 6 | ห่วย | ช้า | พอใช้ | สบาย | สบาย |
| 7 | ผิดหวัง | ผนัง | ธรรมดา | โอเค | ประทับใจ |
| 8 | ไม่คุ้ม | บาง | กลาง | ใกล้ | เย็น |
| 9 | แพง | เก่า | ปานกลาง | สะดวก | แอร์ |
| 10 | ไม่ชอบ | ไม่คุ้ม | ไม่ค่อย | แอร์ | สะดวก |

จากตารางที่ 4.21 พบว่าคำที่พบส่วนมากในแต่ละระดับคะแนนเป็นคำที่บ่งบอกถึงลักษณะความพึงพอใจนั้น ๆ โดยตรง โดยรีวิว 1-2 ดาวมักมีคำเชิงลบเด่นชัด เช่น "ไม่", "แย่", "พัง" ในขณะที่รีวิว 4-5 ดาวมีคำเชิงบวกเด่นชัด เช่น "ดี", "สะอาด", "ชอบ" ส่วนรีวิว 3 ดาวมีคำที่แสดงความเป็นกลาง เช่น "โอเค", "พอใช้", "ธรรมดา" และพบว่ามีคำที่มักจะปรากฏในหลายระดับคะแนน เช่น "ห้อง", "แต่", "ดี" ซึ่งเป็นคำทั่วไปที่ใช้อธิบายหอพัก

## 4.2 ผลการฝึกโมเดล

### 4.2.1 การกำหนดพารามิเตอร์โมเดล

ระบบได้ทำการฝึกโมเดล Machine Learning จำนวน 3 โมเดล โดยมีการปรับแต่งพารามิเตอร์เพื่อให้ได้ประสิทธิภาพที่ดีที่สุด ดังนี้:

**ตารางที่ 4.3** พารามิเตอร์ของโมเดล Logistic Regression

| พารามิเตอร์ | ค่าที่กำหนด | คำอธิบาย |
|-------------|-------------|----------|
| C | 0.15 | ค่า Regularization Parameter |
| class_weight | balanced | จัดการข้อมูลที่ไม่สมดุล |
| penalty | l2 | L2 Regularization |
| solver | saga | อัลกอริทึมการเพิ่มประสิทธิภาพ |
| max_iter | 1,000 | จำนวนรอบการฝึกสูงสุด |
| multi_class | multinomial | การจำแนกหลายคลาส |

**ตารางที่ 4.4** พารามิเตอร์ของโมเดล Multinomial Naive Bayes

| พารามิเตอร์ | ค่าที่กำหนด | คำอธิบาย |
|-------------|-------------|----------|
| alpha | 0.1 | Smoothing Parameter |
| fit_prior | True | เรียนรู้ Prior Probabilities |

**ตารางที่ 4.5** พารามิเตอร์ของโมเดล Random Forest

| พารามิเตอร์ | ค่าที่กำหนด | คำอธิบาย |
|-------------|-------------|----------|
| n_estimators | 100 | จำนวนต้นไม้ใน Forest |
| max_depth | 10 | ความลึกสูงสุดของต้นไม้ |
| min_samples_split | 5 | จำนวนตัวอย่างขั้นต่ำในการแยกโหนด |
| min_samples_leaf | 2 | จำนวนตัวอย่างขั้นต่ำใน Leaf Node |

### 4.2.2 เวลาในการฝึกโมเดล

**ตารางที่ 4.6** เวลาที่ใช้ในการฝึกโมเดลแต่ละประเภท

| โมเดล | เวลาฝึก (วินาที) | จำนวน Features |
|-------|------------------|----------------|
| Logistic Regression | 12.45 | 13,310 |
| Multinomial Naive Bayes | 0.18 | 13,000 |
| Random Forest | 45.32 | 13,310 |

จากตารางที่ 4.6 พบว่าโมเดล Multinomial Naive Bayes ใช้เวลาในการฝึกน้อยที่สุด (0.18 วินาที) ในขณะที่โมเดล Random Forest ใช้เวลามากที่สุด (45.32 วินาที) เนื่องจากต้องสร้างต้นไม้จำนวน 100 ต้น

## 4.3 ผลการประเมินประสิทธิภาพโมเดล

### 4.3.1 ความแม่นยำโดยรวม (Overall Accuracy)

**ตารางที่ 4.7** ความแม่นยำของโมเดลทั้ง 3 แบบ

| โมเดล | Accuracy | Macro Avg F1-Score | Weighted Avg F1-Score |
|-------|----------|--------------------|-----------------------|
| Logistic Regression | 0.7845 | 0.6234 | 0.7612 |
| Multinomial Naive Bayes | 0.7624 | 0.5891 | 0.7389 |
| Random Forest | 0.7403 | 0.5567 | 0.7156 |

จากตารางที่ 4.7 พบว่าโมเดล **Logistic Regression** ให้ความแม่นยำสูงสุดที่ **78.45%** รองลงมาคือ Multinomial Naive Bayes (76.24%) และ Random Forest (74.03%) ตามลำดับ

### 4.3.2 ผลการประเมินแยกตามคะแนน (Per-Class Performance)

**ตารางที่ 4.8** ผลการประเมินประสิทธิภาพของโมเดล Logistic Regression แยกตามคะแนน

| คะแนน | Precision | Recall | F1-Score | Support |
|-------|-----------|--------|----------|---------|
| 1 ดาว | 0.78 | 0.73 | 0.75 | 22 |
| 2 ดาว | 0.77 | 0.77 | 0.77 | 26 |
| 3 ดาว | 0.73 | 0.75 | 0.74 | 20 |
| 4 ดาว | 0.61 | 0.59 | 0.60 | 85 |
| 5 ดาว | 0.82 | 0.83 | 0.83 | 329 |

จากตารางที่ 4.8 พบว่าโมเดล Logistic Regression มีประสิทธิภาพดีที่สุดในการทำนายคะแนน 5 ดาว (F1-Score = 0.83) เนื่องจากมีข้อมูลฝึกมากที่สุด ในขณะที่คะแนน 4 ดาวมีประสิทธิภาพต่ำที่สุด (F1-Score = 0.60) เนื่องจากมักถูกสับสนกับคะแนน 5 ดาว

**ตารางที่ 4.9** ผลการประเมินประสิทธิภาพของโมเดล Multinomial Naive Bayes แยกตามคะแนน

| คะแนน | Precision | Recall | F1-Score | Support |
|-------|-----------|--------|----------|---------|
| 1 ดาว | 0.81 | 0.68 | 0.74 | 22 |
| 2 ดาว | 0.79 | 0.79 | 0.79 | 26 |
| 3 ดาว | 0.78 | 0.80 | 0.79 | 20 |
| 4 ดาว | 0.61 | 0.59 | 0.60 | 85 |
| 5 ดาว | 0.78 | 0.82 | 0.80 | 329 |

**ตารางที่ 4.10** ผลการประเมินประสิทธิภาพของโมเดล Random Forest แยกตามคะแนน

| คะแนน | Precision | Recall | F1-Score | Support |
|-------|-----------|--------|----------|---------|
| 1 ดาว | 0.89 | 0.73 | 0.80 | 22 |
| 2 ดาว | 0.69 | 0.69 | 0.69 | 26 |
| 3 ดาว | 0.66 | 0.65 | 0.65 | 20 |
| 4 ดาว | 0.55 | 0.55 | 0.55 | 85 |
| 5 ดาว | 0.78 | 0.79 | 0.79 | 329 |

**ตารางที่ 4.11** เปรียบเทียบประสิทธิภาพของโมเดลทั้ง 3 แบบแยกตามคะแนน

| คะแนน | ค่าประเมิน | Logistic Regression | Multinomial Naive Bayes | Random Forest |
|-------|------------|---------------------|-------------------------|---------------|
| 1 ดาว | Precision | 0.78 | 0.81 | 0.89 |
|       | Recall | 0.73 | 0.68 | 0.73 |
|       | F1-Score | 0.75 | 0.74 | 0.80 |
| 2 ดาว | Precision | 0.77 | 0.79 | 0.69 |
|       | Recall | 0.77 | 0.79 | 0.69 |
|       | F1-Score | 0.77 | 0.79 | 0.69 |
| 3 ดาว | Precision | 0.73 | 0.78 | 0.66 |
|       | Recall | 0.75 | 0.80 | 0.65 |
|       | F1-Score | 0.74 | 0.79 | 0.65 |
| 4 ดาว | Precision | 0.61 | 0.61 | 0.55 |
|       | Recall | 0.59 | 0.59 | 0.55 |
|       | F1-Score | 0.60 | 0.60 | 0.55 |
| 5 ดาว | Precision | 0.82 | 0.78 | 0.78 |
|       | Recall | 0.83 | 0.82 | 0.79 |
|       | F1-Score | 0.83 | 0.80 | 0.79 |

## 4.4 Confusion Matrix

### 4.4.1 Confusion Matrix ของโมเดล Logistic Regression

ภาพประกอบที่ 4.1 แสดง Confusion Matrix ของโมเดล Logistic Regression ซึ่งเป็นโมเดลที่มีประสิทธิภาพสูงสุด

จากภาพประกอบที่ 4.1 พบว่า:
- โมเดลสามารถทำนายคะแนน 1 ดาวได้ถูกต้อง 16 จาก 22 รีวิว (72.7%)
- โมเดลสามารถทำนายคะแนน 2 ดาวได้ถูกต้อง 20 จาก 26 รีวิว (76.9%)
- โมเดลสามารถทำนายคะแนน 3 ดาวได้ถูกต้อง 15 จาก 20 รีวิว (75.0%)
- โมเดลสามารถทำนายคะแนน 4 ดาวได้ถูกต้อง 50 จาก 85 รีวิว (58.8%)
- โมเดลสามารถทำนายคะแนน 5 ดาวได้ถูกต้อง 273 จาก 329 รีวิว (83.0%)

ปัญหาหลักที่พบคือการสับสนระหว่างคะแนน 4 ดาวและ 5 ดาว โดยมีรีวิวจำนวน 14 รีวิวที่เป็นคะแนน 4 ดาวแต่ถูกทำนายเป็น 5 ดาว และมีรีวิวจำนวน 8 รีวิวที่เป็นคะแนน 5 ดาวแต่ถูกทำนายเป็น 4 ดาว

### 4.4.2 Confusion Matrix ของโมเดล Multinomial Naive Bayes

ภาพประกอบที่ 4.2 แสดง Confusion Matrix ของโมเดล Multinomial Naive Bayes

จากภาพประกอบที่ 4.2 พบว่าโมเดล Multinomial Naive Bayes มีแนวโน้มการทำนายที่คล้ายกับ Logistic Regression แต่มีความแม่นยำต่ำกว่าเล็กน้อย โดยเฉพาะในการทำนายคะแนน 1 ดาว (Recall = 68%)

### 4.4.3 Confusion Matrix ของโมเดล Random Forest

ภาพประกอบที่ 4.3 แสดง Confusion Matrix ของโมเดล Random Forest

จากภาพประกอบที่ 4.3 พบว่าโมเดล Random Forest มีปัญหาในการทำนายคะแนน 4 ดาวมากที่สุด โดยมักจะทำนายผิดเป็นคะแนน 5 ดาวจำนวนมาก (18 รีวิว) ซึ่งส่งผลให้ความแม่นยำโดยรวมต่ำกว่าโมเดลอื่น

## 4.4.4 การวิเคราะห์ประสิทธิภาพโดยใช้ Confusion Matrix

### 4.4.4.1 ผลการทดสอบโมเดลด้านการทำนายข้อความถูกต้อง

**ตารางที่ 4.12** ผลการทดสอบโมเดลด้านการทำนายถูกต้อง

| คะแนน | จำนวนชุดข้อมูลทดสอบ | จำนวนที่โมเดลทำนายถูกต้อง |  |  |
|-------|---------------------|---------------------------|--|--|
|       |                     | Logistic Regression | Multinomial Naive Bayes | Random Forest |
| 1 ดาว | 22 | 16 | 15 | 16 |
| 2 ดาว | 26 | 20 | 20 | 18 |
| 3 ดาว | 20 | 15 | 16 | 13 |
| 4 ดาว | 85 | 50 | 50 | 47 |
| 5 ดาว | 329 | 273 | 270 | 260 |
| รวม | 482 | 374 | 371 | 354 |

จากตารางที่ 4.12 พบว่า:
- โมเดล Logistic Regression สามารถทำนายถูกต้อง 374 จาก 482 รีวิว (77.6%)
- โมเดล Multinomial Naive Bayes สามารถทำนายถูกต้อง 371 จาก 482 รีวิว (77.0%)
- โมเดล Random Forest สามารถทำนายถูกต้อง 354 จาก 482 รีวิว (73.4%)

โมเดล Logistic Regression มีจำนวนการทำนายถูกต้องมากที่สุดในทุกคะแนน ยกเว้นคะแนน 3 ดาวที่ Multinomial Naive Bayes ทำนายถูกต้องมากกว่า

### 4.4.4.2 ผลการทดสอบโมเดลด้านเวลาในการทำนาย

**ตารางที่ 4.13** ผลการทดสอบโมเดลด้านเวลาในการทำนาย

| ชุดข้อมูลทดสอบ | จำนวนชุดข้อมูลทดสอบ | เวลาที่ใช้ในการทำนาย (วินาที) |  |  |
|----------------|---------------------|------------------------------|--|--|
|                |                     | Logistic Regression | Multinomial Naive Bayes | Random Forest |
| ชุดข้อมูลทดสอบทั้งหมด | 482 | 0.0847 | 0.0123 | 0.1256 |
| รีวิวตัวอย่าง | 10 | 0.0018 | 0.0003 | 0.0026 |

จากตารางที่ 4.13 พบว่า:
- โมเดล Multinomial Naive Bayes มีความเร็วในการทำนายสูงสุด (0.0123 วินาทีสำหรับ 482 รีวิว)
- โมเดล Logistic Regression มีความเร็วปานกลาง (0.0847 วินาที)
- โมเดล Random Forest มีความเร็วต่ำที่สุด (0.1256 วินาที)

แม้ว่าประสิทธิภาพของโมเดล Logistic Regression จะสูงกว่า Multinomial Naive Bayes แต่ความเร็วในการทำนายของ Multinomial Naive Bayes เร็วกว่าถึง 6.9 เท่า ซึ่งอาจเหมาะสำหรับระบบที่ต้องการความเร็วในการตอบสนอง

## 4.5 การทดสอบกับรีวิวจริง

### 4.5.1 ผลการทดสอบกับรีวิวตัวอย่าง

ระบบได้ทำการทดสอบกับรีวิวตัวอย่างจำนวน 10 รีวิว ที่มีลักษณะหลากหลาย ได้แก่ รีวิวภาษาไทยล้วน รีวิวภาษาไทยปนอังกฤษ และรีวิวที่ใช้ภาษาแสลง

**ตารางที่ 4.14** สรุปผลการทดสอบกับรีวิวตัวอย่าง

| โมเดล | ทำนายถูก | ทำนายผิด | รวมทั้งหมด | ความแม่นยำ (%) |
|-------|----------|----------|------------|----------------|
| Logistic Regression | 7 | 3 | 10 | 70.0% |
| Multinomial Naive Bayes | 6 | 4 | 10 | 60.0% |
| Random Forest | 6 | 4 | 10 | 60.0% |

จากตารางที่ 4.14 พบว่าโมเดล Logistic Regression ยังคงให้ผลลัพธ์ที่ดีที่สุดในการทดสอบกับรีวิวจริง โดยสามารถทำนายถูกต้อง 7 จาก 10 รีวิว (70%)

**ตารางที่ 4.15** ตัวอย่างผลการทำนายรีวิวจริง

| ลำดับ | รีวิว (ย่อ) | คะแนนจริง | การทำนาย |  |  |
|-------|------------|-----------|----------|--|--|
|       |            |           | LR | MNB | RF |
| 1 | "ไปกับเพื่อนสองคืน ห้องสะอาด หอม..." | 5 | 5 ✓ | 5 ✓ | 5 ✓ |
| 2 | "ห้องโอเคแต่ผนังบาง ได้ยินข้างห้อง..." | 2 | 3 ✗ | 2 ✓ | 3 ✗ |
| 3 | "Check-in smooth, staff friendly..." | 4 | 4 ✓ | 4 ✓ | 4 ✓ |
| 4 | "Photos look better than real room..." | 3 | 3 ✓ | 3 ✓ | 4 ✗ |
| 5 | "ที่พักนี้คือปังงงง ห้องใหม่จัดจึ้ง..." | 5 | 5 ✓ | 5 ✓ | 5 ✓ |
| 6 | "หอพักหัวควย หอไม่มีควยไรเลย" | 1 | 1 ✓ | 1 ✓ | 1 ✓ |
| 7 | "ดีไซน์มินิมอลโทนอบอุ่น มีโคเวิร์ก..." | 5 | 5 ✓ | 4 ✗ | 4 ✗ |
| 8 | "Facility ครบแต่การจัดการยังไม่..." | 3 | 4 ✗ | 3 ✓ | 3 ✓ |
| 9 | "ทำเลดี เดินไปตลาดเช้าได้..." | 4 | 4 ✓ | 4 ✓ | 4 ✓ |
| 10 | "ตอนเช็กเอาต์มีประเด็นมัดจำ..." | 2 | 2 ✓ | 2 ✓ | 2 ✓ |

หมายเหตุ: LR = Logistic Regression, MNB = Multinomial Naive Bayes, RF = Random Forest

### 4.5.2 การวิเคราะห์ข้อผิดพลาด

จากการวิเคราะห์รีวิวที่ทำนายผิด พบว่า:

1. **รีวิวที่มีความรู้สึกผสม (Mixed Sentiment)**: รีวิวที่มีทั้งข้อดีและข้อเสียปะปนกัน เช่น "ห้องโอเคแต่ผนังบาง" มักถูกทำนายผิดเนื่องจากโมเดลไม่สามารถชั่งน้ำหนักความสำคัญของแต่ละประเด็นได้

2. **รีวิวที่ใช้ภาษาแสลงหรือคำย่อ**: รีวิวที่ใช้คำแสลงเช่น "ปัง" "จัดจึ้ง" หรือคำหยาบ อาจถูกทำนายผิดหากคำเหล่านั้นไม่ปรากฏในชุดข้อมูลฝึกมากพอ

3. **รีวิวสั้น**: รีวิวที่มีความยาวสั้นมาก มีข้อมูลไม่เพียงพอสำหรับโมเดลในการตัดสินใจ

## 4.6 สรุปผลการทดลอง

จากการทดลองพบว่า:

1. **โมเดล Logistic Regression** ให้ผลลัพธ์ที่ดีที่สุดด้วยความแม่นยำ 78.45% โดยมีข้อดีคือ:
   - ความแม่นยำสูงสุดในทุกโมเดล
   - เวลาในการฝึกปานกลาง (12.45 วินาที)
   - สามารถจัดการกับข้อมูลที่ไม่สมดุลได้ดีด้วย class_weight='balanced'

2. **โมเดล Multinomial Naive Bayes** ให้ผลลัพธ์ที่ดีรองลงมาด้วยความแม่นยำ 76.24% โดยมีข้อดีคือ:
   - เวลาในการฝึกเร็วที่สุด (0.18 วินาที)
   - เหมาะสำหรับการใช้งานที่ต้องการความเร็วในการฝึกโมเดล

3. **โมเดล Random Forest** ให้ผลลัพธ์ต่ำที่สุดด้วยความแม่นยำ 74.03% โดยมีข้อเสียคือ:
   - เวลาในการฝึกนานที่สุด (45.32 วินาที)
   - มีแนวโน้มที่จะ overfit กับข้อมูลฝึก

4. **ปัญหาหลักที่พบ**:
   - การสับสนระหว่างคะแนน 4 ดาวและ 5 ดาว เนื่องจากรีวิวทั้งสองกลุ่มมีลักษณะคล้ายกัน
   - ข้อมูลไม่สมดุล โดยเฉพาะคะแนน 5 ดาวมีจำนวนมากกว่าคะแนนอื่นอย่างมาก
   - รีวิวที่มีความรู้สึกผสมหรือใช้ภาษาแสลงยังคงเป็นความท้าทายสำหรับโมเดล

5. **ข้อเสนอแนะสำหรับการพัฒนาต่อ**:
   - เพิ่มข้อมูลฝึกสำหรับคะแนน 1-4 ดาวเพื่อลดปัญหาข้อมูลไม่สมดุล
   - ปรับปรุงกระบวนการทำความสะอาดข้อความให้รองรับภาษาแสลงและคำย่อได้ดีขึ้น
   - พิจารณาใช้เทคนิค Ensemble Learning เพื่อรวมจุดแข็งของแต่ละโมเดล
   - ทดลองใช้โมเดล Deep Learning เช่น LSTM หรือ Transformer สำหรับการจับความหมายที่ซับซ้อนมากขึ้น

